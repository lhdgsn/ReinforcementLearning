{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "This notebook introduces and demonstrates the basic functionality of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "PyTorch tensors are the base variable used for computation, and can the dimension of most classic variables (scalar, vector, matrix). They are similar in use to Numpy ndarrays.\n",
    "\n",
    "torch.tensor(data) creates tensor from data\n",
    "torch.* creates a tensor with given initialization (empty, zeros, ones, random, etc)\n",
    "torch.*_like(input) creates a tensor with a given initialization, but copies the properties of the input (size, dtype, etc)\n",
    "\n",
    "see https://pytorch.org/docs/master/torch.html#tensor-creation-ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty matrix\n",
    "x = torch.empty(5,3)\n",
    "\n",
    "# randomly initialize a vector\n",
    "x = torch.rand(4)\n",
    "\n",
    "# zero initialize a matrix of datatrype long\n",
    "x = torch.zeros(3,3,dtype=torch.long)\n",
    "\n",
    "# construct a tensor from data\n",
    "x = torch.tensor([[5.5, 3], [6, 2.1]])\n",
    "\n",
    "# create a copy of an existing tensor\n",
    "y = torch.zeros_like(x)\n",
    "\n",
    "# find the size\n",
    "y.size();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "There are multiple syntaxes for operations.\n",
    "see all operations here https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "\n",
    "# addition\n",
    "z = x + y\n",
    "\n",
    "z = torch.add(x,y)\n",
    "\n",
    "z = torch.empty_like(x) # provides output tensor\n",
    "torch.add(x, y, out=z)\n",
    "\n",
    "y.add_(x); # adds inplace (adds x to y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numpy\n",
    "Most PyTorch operations are basically the same as the Numpy equivalent, and it's easy to convert variables between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from torch to numpy\n",
    "x = torch.ones(5)\n",
    "y = x.numpy() # note that they now share memory (changing one changes the other)\n",
    "\n",
    "# convert from numpy to torch\n",
    "x = np.ones(5)\n",
    "y = torch.from_numpy(x) # again, they share the same memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with gradients\n",
    "The autograd package provides automatic differentiation for all tensor operations.\n",
    "\n",
    "The *requires_grad* flag for a tensor indicates that it will be part backpropagation. All results of calculations involving the initial tensor will have the same flag.\n",
    "\n",
    "The *.grad* attribute stores the gradients calculated during backpropagation\n",
    "\n",
    "*X.backward()* backpropagates from variable X. If X is non-scalar, then you need to specify gradients (X.backward(gradients)) \n",
    "\n",
    "see documentation here: https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f86e028cc50>\n",
      "<MeanBackward1 object at 0x7f86e028cc50>\n",
      "tensor([[ 0.5000,  0.5000],\n",
      "        [ 0.5000,  0.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "# the grad_fn attribute tracks which gradient operation will be needed\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y.mean()\n",
    "print(z.grad_fn)\n",
    "\n",
    "# backpropagate\n",
    "z.backward()\n",
    "\n",
    "# print the gradients\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "The neural network package torch.nn depends on autograd to define models and differentiate them. nn.Module defines the layers of the net, and the method forward() performs forward propagation.\n",
    "\n",
    "As an example, let's work on the MNIST dataset using a convnet.\n",
    "<img src=\"mnist.png\">\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html?highlight=nn%20conv2d#torch.nn.Conv2d\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html?highlight=nn%20linear#torch.nn.Linear\n",
    "\n",
    "* Step 1: initialize the weights\n",
    "* Step 2: define forward propagation (backward propagation is done automatically by autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # declare the kernels for the two convolution operations\n",
    "        ## convolution 1: 1 32x32 input image, 6 output images, 5x5 kernel\n",
    "        ## convolution 2: 6 14x14 input images, 16 output images, 5x5 kernel\n",
    "        ## nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # declare the weights for the fully-connected layers\n",
    "        ## nn.Linear(in_features, out_features, bias=True)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # define forward propagation\n",
    "    def forward(self, x):\n",
    "        # convolution 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # maxpool 1 (2x2 window)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # convolution 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # maxpool 2 (2x2 window)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # reshape the data into a vector\n",
    "        x = x.view(-1, self.n_flat_features(x))\n",
    "        # fully-connected 1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # fully-connected 2\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # output\n",
    "        return self.fc3(x)\n",
    "    \n",
    "    # calculates the total number of features\n",
    "    def n_flat_features(self, x):\n",
    "        sz = x.size()[1:]\n",
    "        n_features = 1\n",
    "        for s in sz:\n",
    "            n_features *= s\n",
    "        return n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the net\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# try a random 32x32 input\n",
    "# torch.nn only accepts minibatch inputs (4D vectors)\n",
    "# size should be nSamples x nChannels x height x width\n",
    "data_in = torch.randn(1, 1, 32, 32)\n",
    "out = net(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the loss function and backpropagating\n",
    "Calculate how close the neural net's output is to the desired value/classification\n",
    "torch.nn has a number of loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.6260)\n"
     ]
    }
   ],
   "source": [
    "# for example, use mean squared error loss\n",
    "target = torch.range(1,10)  # a dummy target\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)\n",
    "\n",
    "# zero the gradients\n",
    "net.zero_grad()\n",
    "# backprop with random gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "# update each of the parameters: weight = weight - learning_rate * gradient \n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for better gradient descent implementations, use torch.optim\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # create your optimizer\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# # in your training loop:\n",
    "# optimizer.zero_grad()   # zero the gradient buffers\n",
    "# output = net(input)\n",
    "# loss = criterion(output, target)\n",
    "# loss.backward()\n",
    "# optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier (full example)\n",
    "Using the CIFAR10 dataset, which has images of size 3 x 32 x 32 labelled as classes ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "\n",
    "For list of available datasets, see https://pytorch.org/docs/master/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision # contains dataloaders for common datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# import the CIFAR10 dataset\n",
    "## imported images are PIL images of range [0,1], convert to tensor of normalized range [-1,1]\n",
    "## transforms.Normalize(mean, std_dev)\n",
    "T = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=T)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=T)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.203\n",
      "[1,  4000] loss: 1.858\n",
      "[1,  6000] loss: 1.684\n",
      "[1,  8000] loss: 1.611\n",
      "[1, 10000] loss: 1.536\n",
      "[1, 12000] loss: 1.464\n",
      "[2,  2000] loss: 1.418\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.338\n",
      "[2,  8000] loss: 1.323\n",
      "[2, 10000] loss: 1.305\n",
      "[2, 12000] loss: 1.274\n",
      "[3,  2000] loss: 1.199\n",
      "[3,  4000] loss: 1.206\n",
      "[3,  6000] loss: 1.197\n",
      "[3,  8000] loss: 1.192\n",
      "[3, 10000] loss: 1.163\n",
      "[3, 12000] loss: 1.155\n",
      "[4,  2000] loss: 1.087\n",
      "[4,  4000] loss: 1.087\n",
      "[4,  6000] loss: 1.084\n",
      "[4,  8000] loss: 1.077\n",
      "[4, 10000] loss: 1.096\n",
      "[4, 12000] loss: 1.092\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# copy above network (comments removed)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # define forward propagation\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "# use cross-entropy loss and SGD with momentum\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(4):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forwardprop\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ae8481ed38bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GroundTruth: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imshow' is not defined"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  truck  frog truck  ship\n"
     ]
    }
   ],
   "source": [
    "output = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 66 %\n",
      "Accuracy of   car : 69 %\n",
      "Accuracy of  bird : 45 %\n",
      "Accuracy of   cat : 32 %\n",
      "Accuracy of  deer : 61 %\n",
      "Accuracy of   dog : 55 %\n",
      "Accuracy of  frog : 75 %\n",
      "Accuracy of horse : 53 %\n",
      "Accuracy of  ship : 73 %\n",
      "Accuracy of truck : 72 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
